calc info gain
    discrete
        just calculate info.

    continuous
        for each bi-partition, calculate info.
        pick best one and return value.


node:
    attribute = (var_name, var_type)
    children = {var_value: node}
        or {left: node, right: node}

    result = 'res_string'

    def distribution(self, data):
        return distribution (as a histogram)

Now I need a way to predict continuous data -> use piecewise-constant approach.
    entropy gets replaced with variance.
    info gain is variance of parent set - sum(weight_i * v_i) for all i in children set
Look into cross-validation, pruning, etc.

try:
    predict age

try:
    use age,ticket, fare -> survival

try:
    random forest:
        each tree gets a different subset of data (with replacement!)
        at each step, each tree randomly compares only two of the N attributes to split on.
